{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda-12.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_HOME'] = \"/usr/local/cuda-12.4\"\n",
    "print(os.environ['CUDA_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mjknowles/anaconda3/envs/rag-from-scratch/bin:/home/mjknowles/.vscode-server/bin/863d2581ecda6849923a2118d93a088b0745d9d6/bin/remote-cli:/home/mjknowles/.local/bin:/usr/local/cuda-12.4/bin:/home/mjknowles/anaconda3/envs/rag-from-scratch/bin:/home/mjknowles/anaconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/WINDOWS/system32:/mnt/c/WINDOWS:/mnt/c/WINDOWS/System32/Wbem:/mnt/c/WINDOWS/System32/WindowsPowerShell/v1.0:/mnt/c/WINDOWS/System32/OpenSSH:/mnt/c/Program Files/Docker/Docker/resources/bin:/mnt/c/Program Files/Git/cmd:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/Users/mjkno/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/mjkno/AppData/Local/Programs/Microsoft VS Code/bin:/snap/bin\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-readers-file in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (0.1.11)\n",
      "Requirement already satisfied: pymupdf in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (1.23.26)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-readers-file) (4.12.3)\n",
      "Requirement already satisfied: bs4<0.0.3,>=0.0.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-readers-file) (0.0.2)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-readers-file) (0.10.21.post1)\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-readers-file) (4.1.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-readers-file) (0.0.26)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.22 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pymupdf) (1.23.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.14.2)\n",
      "Requirement already satisfied: pandas in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.9.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.14.0)\n",
      "Requirement already satisfied: click in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-vector-stores-postgres in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (0.1.4.post1)\n",
      "Requirement already satisfied: asyncpg<0.30.0,>=0.29.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-vector-stores-postgres) (0.29.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.20 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-vector-stores-postgres) (0.10.21.post1)\n",
      "Requirement already satisfied: pgvector<0.3.0,>=0.2.4 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-vector-stores-postgres) (0.2.5)\n",
      "Requirement already satisfied: psycopg2-binary<3.0.0,>=2.9.9 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-vector-stores-postgres) (2.9.9)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=2.0.25 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from sqlalchemy[asyncio]<3.0.0,>=2.0.25->llama-index-vector-stores-postgres) (2.0.28)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from asyncpg<0.30.0,>=0.29.0->llama-index-vector-stores-postgres) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.3.1)\n",
      "Requirement already satisfied: httpx in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.14.2)\n",
      "Requirement already satisfied: pandas in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from sqlalchemy<3.0.0,>=2.0.25->sqlalchemy[asyncio]<3.0.0,>=2.0.25->llama-index-vector-stores-postgres) (3.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.9.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.6.4)\n",
      "Requirement already satisfied: anyio in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.14.0)\n",
      "Requirement already satisfied: click in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2024.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (24.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.20->llama-index-vector-stores-postgres) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: llama-index-embeddings-huggingface in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (0.1.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.21.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.10.21.post1)\n",
      "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (2.2.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (4.39.0)\n",
      "Requirement already satisfied: filelock in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.1)\n",
      "Requirement already satisfied: requests in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (24.0)\n",
      "Requirement already satisfied: aiohttp in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.3)\n",
      "Requirement already satisfied: pydantic<3.0,>1.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.4)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.28)\n",
      "Requirement already satisfied: dataclasses-json in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.2)\n",
      "Requirement already satisfied: pandas in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: sympy in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.4.99)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.4.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.9.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Requirement already satisfied: anyio in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (4.3.0)\n",
      "Requirement already satisfied: certifi in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.6)\n",
      "Requirement already satisfied: sniffio in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: click in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.3.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from requests->huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-readers-file pymupdf\n",
    "%pip install llama-index-vector-stores-postgres\n",
    "%pip install llama-index-embeddings-huggingface\n",
    "#%pip install llama-index-llms-llama-cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 CUDAFLAGS=\"-arch=all -lcublas\" pip install llama-cpp-python --upgrade --force-reinstall --no-cache-dir --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\"\n",
      "env: FORCE_CMAKE=1\n",
      "env: \"CUDAFLAGS=-arch=all -lcublas\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pip 23.3.1 from /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pip (python 3.11)\n",
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.2.57.tar.gz (36.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.9/36.9 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l  Running command pip subprocess to install build dependencies\n",
      "  Collecting scikit-build-core>=0.5.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
      "    Using cached scikit_build_core-0.8.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Collecting packaging>=20.9 (from scikit-build-core>=0.5.1->scikit-build-core[pyproject]>=0.5.1)\n",
      "    Using cached packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Collecting pathspec>=0.10.1 (from scikit-build-core[pyproject]>=0.5.1)\n",
      "    Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Collecting pyproject-metadata>=0.5 (from scikit-build-core[pyproject]>=0.5.1)\n",
      "    Using cached pyproject_metadata-0.7.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Using cached scikit_build_core-0.8.2-py3-none-any.whl (140 kB)\n",
      "  Using cached packaging-24.0-py3-none-any.whl (53 kB)\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "  Using cached pyproject_metadata-0.7.1-py3-none-any.whl (7.4 kB)\n",
      "  Installing collected packages: pathspec, packaging, scikit-build-core, pyproject-metadata\n",
      "  Successfully installed packaging-24.0 pathspec-0.12.1 pyproject-metadata-0.7.1 scikit-build-core-0.8.2\n",
      "\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l  Running command Getting requirements to build wheel\n",
      "\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l  Running command pip subprocess to install backend dependencies\n",
      "  Collecting cmake>=3.21\n",
      "    Using cached cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "  Collecting ninja>=1.5\n",
      "    Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
      "  Using cached cmake-3.28.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "  Installing collected packages: ninja, cmake\n",
      "  Successfully installed cmake-3.28.3 ninja-1.11.1.1\n",
      "\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l  Running command Preparing metadata (pyproject.toml)\n",
      "  \u001b[92m***\u001b[0m \u001b[1m\u001b[92mscikit-build-core 0.8.2\u001b[0m using \u001b[94mCMake 3.28.3\u001b[0m \u001b[91m(metadata_wheel)\u001b[0m\u001b[0m\n",
      "\u001b[?25hdone\n",
      "Collecting llama-index-llms-llama-cpp\n",
      "  Obtaining dependency information for llama-index-llms-llama-cpp from https://files.pythonhosted.org/packages/6e/f5/149f43c6eb831c864ccae37611a5bf996eb89da39fa04f5ff7496bf87a42/llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl.metadata (695 bytes)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-cpp-python)\n",
      "  Obtaining dependency information for typing-extensions>=4.5.0 from https://files.pythonhosted.org/packages/f9/de/dc04a3ea60b22624b51c703a84bbe0184abcd1d0b9bc8074b5d6b7ab90bb/typing_extensions-4.10.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Link requires a different Python (3.11.8 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/3a/be/650f9c091ef71cb01d735775d554e068752d3ff63d7943b26316dc401749/numpy-1.21.2.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.8 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/5f/d6/ad58ded26556eaeaa8c971e08b6466f17c4ac4d786cd3d800e26ce59cc01/numpy-1.21.3.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.8 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/fb/48/b0708ebd7718a8933f0d3937513ef8ef2f4f04529f1f66ca86d873043921/numpy-1.21.4.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.8 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/c2/a8/a924a09492bdfee8c2ec3094d0a13f2799800b4fdc9c890738aeeb12c72e/numpy-1.21.5.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "  Link requires a different Python (3.11.8 not in: '>=3.7,<3.11'): https://files.pythonhosted.org/packages/45/b7/de7b8e67f2232c26af57c205aaad29fe17754f793404f59c8a730c7a191a/numpy-1.21.6.zip (from https://pypi.org/simple/numpy/) (requires-python:>=3.7,<3.11)\n",
      "Collecting numpy>=1.20.0 (from llama-cpp-python)\n",
      "  Obtaining dependency information for numpy>=1.20.0 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting diskcache>=5.6.1 (from llama-cpp-python)\n",
      "  Obtaining dependency information for diskcache>=5.6.1 from https://files.pythonhosted.org/packages/3f/27/4570e78fc0bf5ea0ca45eb1de3818a23787af9b390c0b0a0033a1b8236f9/diskcache-5.6.3-py3-none-any.whl.metadata\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting jinja2>=2.11.3 (from llama-cpp-python)\n",
      "  Obtaining dependency information for jinja2>=2.11.3 from https://files.pythonhosted.org/packages/30/6d/6de6be2d02603ab56e72997708809e8a5b0fbfee080735109b40a3564843/Jinja2-3.1.3-py3-none-any.whl.metadata\n",
      "  Downloading Jinja2-3.1.3-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for llama-index-core<0.11.0,>=0.10.1 from https://files.pythonhosted.org/packages/03/e8/1fbb4fa24395062fa09256fecaca123de86fb1d989eae1ab0067b64f982b/llama_index_core-0.10.21.post1-py3-none-any.whl.metadata\n",
      "  Downloading llama_index_core-0.10.21.post1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.3->llama-cpp-python)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/97/18/c30da5e7a0e7f4603abfc6780574131221d9148f323752c2755d48abad30/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for PyYAML>=6.0.1 from https://files.pythonhosted.org/packages/7b/5e/efd033ab7199a0b2044dab3b9f7a4f6670e6a52c089de572e928d2873b06/PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for SQLAlchemy>=1.4.49 from https://files.pythonhosted.org/packages/c2/f8/06f5680d65d2f5fda9828b2131981ac81bce4003b4a04486c8b715c365f5/SQLAlchemy-2.0.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for aiohttp<4.0.0,>=3.8.6 from https://files.pythonhosted.org/packages/84/bb/74c9f32e1a76fab04b54ed6cd4b0dc4a07bd9dc6f3bb37f630149a9c3068/aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for dataclasses-json from https://files.pythonhosted.org/packages/91/ca/7219b838086086972e662c19e908694bdc6744537fb41b70392501b8b5e4/dataclasses_json-0.6.4-py3-none-any.whl.metadata\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for deprecated>=1.2.9.3 from https://files.pythonhosted.org/packages/20/8d/778b7d51b981a96554f29136cd59ca7880bf58094338085bcf2a979a0e6a/Deprecated-1.2.14-py2.py3-none-any.whl.metadata\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for dirtyjson<2.0.0,>=1.0.8 from https://files.pythonhosted.org/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl.metadata\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/93/6d/66d48b03460768f523da62a57a7e14e5e95fdf339d79e996ce3cecda2cdb/fsspec-2024.3.1-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for httpx from https://files.pythonhosted.org/packages/41/7b/ddacf6dcebb42466abd03f368782142baa82e08fc0c1f8eaa05b4bae87d5/httpx-0.27.0-py3-none-any.whl.metadata\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for llamaindex-py-client<0.2.0,>=0.1.13 from https://files.pythonhosted.org/packages/94/ad/f0f8026cf1545b8b37ba5ad61dc62877745cf64b40be60be2310d779a8d1/llamaindex_py_client-0.1.13-py3-none-any.whl.metadata\n",
      "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl.metadata (762 bytes)\n",
      "Collecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for nest-asyncio<2.0.0,>=1.5.8 from https://files.pythonhosted.org/packages/a0/c4/c2971a3ba4c6103a3d10c4b0f24f461ddc027f0f09763220cf35ca1401b3/nest_asyncio-1.6.0-py3-none-any.whl.metadata\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for networkx>=3.0 from https://files.pythonhosted.org/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for nltk<4.0.0,>=3.8.1 from https://files.pythonhosted.org/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl.metadata\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for openai>=1.1.0 from https://files.pythonhosted.org/packages/c5/e7/5254c1c37a475d68b9ec11397a2fa967a06ef5e58e41755857f35b26511b/openai-1.14.2-py3-none-any.whl.metadata\n",
      "  Downloading openai-1.14.2-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting pandas (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for pandas from https://files.pythonhosted.org/packages/d4/47/1ccf9f62d2674d3ca3e95452c5f9dd114234d1535dec77c96528bf6a31fc/pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for pillow>=9.0.0 from https://files.pythonhosted.org/packages/66/9c/2e1877630eb298bbfd23f90deeec0a3f682a4163d5ca9f178937de57346c/pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for requests>=2.31.0 from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for tenacity<9.0.0,>=8.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for tiktoken>=0.3.3 from https://files.pythonhosted.org/packages/63/ec/3856d242f580d0d755c3be9024dd11b17b3363dd0c7c3000e3bdecb40d84/tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for tqdm<5.0.0,>=4.66.1 from https://files.pythonhosted.org/packages/2a/14/e75e52d521442e2fcc9f1df3c5e456aead034203d4797867980de558ab34/tqdm-4.66.2-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for typing-inspect>=0.8.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for attrs>=17.3.0 from https://files.pythonhosted.org/packages/e0/44/827b2a91a5816512fcaf3cc4ebc465ccd5d598c45cefa6703fcf4a79018f/attrs-23.2.0-py3-none-any.whl.metadata\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b3/c9/0bc5ee7e1f5cc7358ab67da0b7dfe60fbd05c254cea5c6108e7d1ae28c63/frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/52/ec/be54a3ad110f386d5bd7a9a42a4ff36b3cd723ebe597f41073a73ffa16b8/multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.0 from https://files.pythonhosted.org/packages/9f/ea/94ad7d8299df89844e666e4aa8a0e9b88e02416cd6a7dd97969e9eae5212/yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for wrapt<2,>=1.10 from https://files.pythonhosted.org/packages/6e/52/2da48b35193e39ac53cfb141467d9f259851522d0e8c87153f0ba4205fb1/wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting pydantic>=1.10 (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for pydantic>=1.10 from https://files.pythonhosted.org/packages/e5/f3/8296f550276194a58c5500d55b19a27ae0a5a3a51ffef66710c58544b32d/pydantic-2.6.4-py3-none-any.whl.metadata\n",
      "  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting anyio (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for anyio from https://files.pythonhosted.org/packages/14/fd/2f20c40b45e4fb4324834aea24bd4afdf1143390242c0b33774da0e2e34f/anyio-4.3.0-py3-none-any.whl.metadata\n",
      "  Downloading anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for certifi from https://files.pythonhosted.org/packages/ba/06/a07f096c664aeb9f01624f858c3add0a4e913d6c96257acb4fce61e7de14/certifi-2024.2.2-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/2c/93/13f25f2f78646bab97aee7680821e30bd85b2ff0fc45d5fdf5393b79716d/httpcore-1.0.4-py3-none-any.whl.metadata\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting idna (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for idna from https://files.pythonhosted.org/packages/c2/e7/a82b05cf63a603df6e68d59ae6a68bf5064484a0718ea5033660af4b54a9/idna-3.6-py3-none-any.whl.metadata\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sniffio (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for sniffio from https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for h11<0.15,>=0.13 from https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl.metadata\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for joblib from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for regex>=2021.8.3 from https://files.pythonhosted.org/packages/8d/6b/2f6478814954c07c04ba60b78d688d3d7bab10d786e0b6c1db607e4f6673/regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m472.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/40/26/f35951c45070edc957ba40a5b1db3cf60a9dbb1b350c2d5bef03e01e61de/charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/a2/73/a68704750a7679d0b6d3ad7aa8d4da8e14e151ae82e6fee774e6e0d05ec8/urllib3-2.2.1-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/c6/1f/12d5a6cc26e8b483c2e7975f9c22e088ac735c0d8dcb8a8f72d31a4e5f04/greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata\n",
      "  Downloading greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for mypy-extensions>=0.3.0 from https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl.metadata\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/38/04/37055b7013dfaaf66e3a9a51e46857cc9be151476a891b995fa70da7e139/marshmallow-3.21.1-py3-none-any.whl.metadata\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for python-dateutil>=2.8.2 from https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for pytz>=2020.1 from https://files.pythonhosted.org/packages/9c/3d/a121f284241f08268b21359bd425f7d4825cffc5ac5cd0e1b3d82ffd2b10/pytz-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/65/58/f9c9e6be752e9fcb8b6a0ee9fb87e6e7a1f6bcab2cdc73f02bb7ba91ada0/tzdata-2024.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting packaging>=17.0 (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for packaging>=17.0 from https://files.pythonhosted.org/packages/49/df/1fceb2f8900f8639e278b056416d49134fb8d84c5942ffaa01ad34782422/packaging-24.0-py3-none-any.whl.metadata\n",
      "  Downloading packaging-24.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for pydantic-core==2.16.3 from https://files.pythonhosted.org/packages/18/0e/1e39cfbffa57e92ab9f1f0869b32ead8a48ab11e4a373421d625f25fcb26/pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-llama-cpp)\n",
      "  Obtaining dependency information for six>=1.5 from https://files.pythonhosted.org/packages/d9/5a/e7c31adbe875f2abbb91bd84cf2dc52d792b5a01506781dbcf25c91daf11/six-1.16.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading llama_index_llms_llama_cpp-0.1.3-py3-none-any.whl (5.1 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m157.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Jinja2-3.1.3-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.2/133.2 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_core-0.10.21.post1-py3-none-any.whl (15.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Downloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m342.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m414.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading pandas-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (140 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.3/140.3 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (620 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m620.0/620.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (785 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m785.1/785.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wrapt-1.16.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (328 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.1/328.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.0-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.5/53.5 kB\u001b[0m \u001b[31m277.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l  Running command Building wheel for llama-cpp-python (pyproject.toml)\n",
      "  \u001b[92m***\u001b[0m \u001b[1m\u001b[92mscikit-build-core 0.8.2\u001b[0m using \u001b[94mCMake 3.28.3\u001b[0m \u001b[91m(wheel)\u001b[0m\u001b[0m\n",
      "  \u001b[92m***\u001b[0m \u001b[1mConfiguring CMake...\u001b[0m\n",
      "  2024-03-21 11:13:15,656 - scikit_build_core - WARNING - libdir/ldlibrary: /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/libpython3.11.a is not a real file!\n",
      "  2024-03-21 11:13:15,656 - scikit_build_core - WARNING - Can't find a Python library, got libdir=/home/mjknowles/anaconda3/envs/rag-from-scratch/lib, ldlibrary=libpython3.11.a, multiarch=x86_64-linux-gnu, masd=None\n",
      "  \u001b[33mCMake Warning:\n",
      "    Ignoring extra path from command line:\n",
      "\n",
      "     \"\"-DLLAMA_CUBLAS=on\"\"\n",
      "\n",
      "  \u001b[0m\n",
      "  loading initial cache file /tmp/tmpfn0ar2_l/build/CMakeInit.txt\n",
      "  -- The C compiler identification is GNU 11.4.0\n",
      "  -- The CXX compiler identification is GNU 11.4.0\n",
      "  -- Detecting C compiler ABI info\n",
      "  -- Detecting C compiler ABI info - done\n",
      "  -- Check for working C compiler: /usr/bin/cc - skipped\n",
      "  -- Detecting C compile features\n",
      "  -- Detecting C compile features - done\n",
      "  -- Detecting CXX compiler ABI info\n",
      "  -- Detecting CXX compiler ABI info - done\n",
      "  -- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
      "  -- Detecting CXX compile features\n",
      "  -- Detecting CXX compile features - done\n",
      "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
      "  -- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Success\n",
      "  -- Found Threads: TRUE\n",
      "  -- Warning: ccache not found - consider installing it for faster compilation or disable this warning with LLAMA_CCACHE=OFF\n",
      "  -- CMAKE_SYSTEM_PROCESSOR: x86_64\n",
      "  -- x86 detected\n",
      "  \u001b[33mCMake Warning (dev) at CMakeLists.txt:21 (install):\n",
      "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
      "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "  \u001b[0m\n",
      "  \u001b[33mCMake Warning (dev) at CMakeLists.txt:30 (install):\n",
      "    Target llama has PUBLIC_HEADER files but no PUBLIC_HEADER DESTINATION.\n",
      "  This warning is for project developers.  Use -Wno-dev to suppress it.\n",
      "  \u001b[0m\n",
      "  -- Configuring done (0.5s)\n",
      "  -- Generating done (0.0s)\n",
      "  -- Build files have been written to: /tmp/tmpfn0ar2_l/build\n",
      "  \u001b[92m***\u001b[0m \u001b[1mBuilding project with \u001b[94mNinja\u001b[0m...\u001b[0m\n",
      "  Change Dir: '/tmp/tmpfn0ar2_l/build'\n",
      "\n",
      "  Run Build Command(s): /tmp/pip-build-env-lvni2sxs/normal/lib/python3.11/site-packages/ninja/data/bin/ninja -v\n",
      "  [1/23] cd /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp && /tmp/pip-build-env-lvni2sxs/normal/lib/python3.11/site-packages/cmake/data/bin/cmake -DMSVC= -DCMAKE_C_COMPILER_VERSION=11.4.0 -DCMAKE_C_COMPILER_ID=GNU -DCMAKE_VS_PLATFORM_NAME= -DCMAKE_C_COMPILER=/usr/bin/cc -P /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/../scripts/gen-build-info-cpp.cmake\n",
      "  -- Found Git: /usr/bin/git (found version \"2.34.1\")\n",
      "  [2/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600  -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/build-info.cpp\n",
      "  [3/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/console.cpp\n",
      "  [4/23] /usr/bin/cc -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/ggml-alloc.c\n",
      "  [5/23] /usr/bin/cc -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/ggml-backend.c\n",
      "  [6/23] /usr/bin/c++ -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/llava.cpp\n",
      "  [7/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/grammar-parser.cpp\n",
      "  [8/23] /usr/bin/c++  -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/../../common -O3 -DNDEBUG -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/llava-cli.cpp\n",
      "  [9/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/sampling.cpp\n",
      "  [10/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/unicode.cpp\n",
      "  [11/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/train.cpp\n",
      "  [12/23] /usr/bin/cc -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/ggml-quants.c\n",
      "  [13/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -MF vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o.d -o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/common/common.cpp\n",
      "  [14/23] /usr/bin/cc -DGGML_SCHED_MAX_COPIES=4 -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu11 -fPIC -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wdouble-promotion -march=native -MD -MT vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -MF vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o.d -o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/ggml.c\n",
      "  [15/23] : && /tmp/pip-build-env-lvni2sxs/normal/lib/python3.11/site-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/libggml_static.a && /usr/bin/ar qc vendor/llama.cpp/libggml_static.a  vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o && /usr/bin/ranlib vendor/llama.cpp/libggml_static.a && :\n",
      "  [16/23] : && /usr/bin/cc -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libggml_shared.so -o vendor/llama.cpp/libggml_shared.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o   && :\n",
      "  [17/23] /usr/bin/c++ -DLLAMA_BUILD -DLLAMA_SHARED -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/../.. -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/../../common -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -fPIC -Wno-cast-qual -MD -MT vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -MF vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o.d -o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/examples/llava/clip.cpp\n",
      "  [18/23] : && /tmp/pip-build-env-lvni2sxs/normal/lib/python3.11/site-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/examples/llava/libllava_static.a && /usr/bin/ar qc vendor/llama.cpp/examples/llava/libllava_static.a  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o && /usr/bin/ranlib vendor/llama.cpp/examples/llava/libllava_static.a && :\n",
      "  [19/23] /usr/bin/c++ -DGGML_SCHED_MAX_COPIES=4 -DLLAMA_BUILD -DLLAMA_SHARED -D_GNU_SOURCE -D_XOPEN_SOURCE=600 -Dllama_EXPORTS -I/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/. -O3 -DNDEBUG -std=gnu++11 -fPIC -Wmissing-declarations -Wmissing-noreturn -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wno-array-bounds -Wno-format-truncation -Wextra-semi -march=native -MD -MT vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -MF vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o.d -o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o -c /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/vendor/llama.cpp/llama.cpp\n",
      "  [20/23] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllama.so -o vendor/llama.cpp/libllama.so vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o vendor/llama.cpp/CMakeFiles/llama.dir/llama.cpp.o vendor/llama.cpp/CMakeFiles/llama.dir/unicode.cpp.o   && :\n",
      "  [21/23] : && /tmp/pip-build-env-lvni2sxs/normal/lib/python3.11/site-packages/cmake/data/bin/cmake -E rm -f vendor/llama.cpp/common/libcommon.a && /usr/bin/ar qc vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/common/CMakeFiles/build_info.dir/build-info.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/common.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/sampling.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/console.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/grammar-parser.cpp.o vendor/llama.cpp/common/CMakeFiles/common.dir/train.cpp.o && /usr/bin/ranlib vendor/llama.cpp/common/libcommon.a && :\n",
      "  [22/23] : && /usr/bin/c++ -fPIC -O3 -DNDEBUG   -shared -Wl,-soname,libllava.so -o vendor/llama.cpp/examples/llava/libllava.so vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-alloc.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-backend.c.o vendor/llama.cpp/CMakeFiles/ggml.dir/ggml-quants.c.o  -Wl,-rpath,/tmp/tmpfn0ar2_l/build/vendor/llama.cpp:  vendor/llama.cpp/libllama.so && :\n",
      "  [23/23] : && /usr/bin/c++ -O3 -DNDEBUG  vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/llava.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava.dir/clip.cpp.o vendor/llama.cpp/examples/llava/CMakeFiles/llava-cli.dir/llava-cli.cpp.o -o vendor/llama.cpp/examples/llava/llava-cli  -Wl,-rpath,/tmp/tmpfn0ar2_l/build/vendor/llama.cpp:  vendor/llama.cpp/common/libcommon.a  vendor/llama.cpp/libllama.so && :\n",
      "\n",
      "  \u001b[92m***\u001b[0m \u001b[1mInstalling project into wheel...\u001b[0m\n",
      "  -- Install configuration: \"Release\"\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/lib/libggml_shared.so\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/lib/cmake/Llama/LlamaConfig.cmake\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/lib/cmake/Llama/LlamaConfigVersion.cmake\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/include/ggml.h\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/include/ggml-alloc.h\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/include/ggml-backend.h\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/lib/libllama.so\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/include/llama.h\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/bin/convert.py\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/bin/convert-lora-to-ggml.py\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/llama_cpp/libllama.so\n",
      "  -- Installing: /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/llama_cpp/libllama.so\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/lib/libllava.so\n",
      "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpfn0ar2_l/wheel/platlib/lib/libllava.so\" to \"\"\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/bin/llava-cli\n",
      "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpfn0ar2_l/wheel/platlib/bin/llava-cli\" to \"\"\n",
      "  -- Installing: /tmp/tmpfn0ar2_l/wheel/platlib/llama_cpp/libllava.so\n",
      "  -- Set non-toolchain portion of runtime path of \"/tmp/tmpfn0ar2_l/wheel/platlib/llama_cpp/libllava.so\" to \"\"\n",
      "  -- Installing: /tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/llama_cpp/libllava.so\n",
      "  -- Set non-toolchain portion of runtime path of \"/tmp/pip-install-ioji1n95/llama-cpp-python_edd46516d2dc42de8c4328335e996555/llama_cpp/libllava.so\" to \"\"\n",
      "  \u001b[92m***\u001b[0m \u001b[1mMaking wheel...\u001b[0m\n",
      "  \u001b[92m***\u001b[0m \u001b[1mCreated\u001b[22m llama_cpp_python-0.2.57-cp311-cp311-manylinux_2_35_x86_64.whl...\u001b[0m\n",
      "\u001b[?25hdone\n",
      "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.57-cp311-cp311-manylinux_2_35_x86_64.whl size=2872728 sha256=75313e0ab0ebeb1c73af240b4fa34907b0f0a82e4cf0f347e8394371ab741771\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n50mchk3/wheels/da/32/73/1fec1c5d23b48778eded302829d37a01b597f3e42d3e60e681\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: pytz, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, sniffio, six, regex, PyYAML, pillow, packaging, numpy, networkx, nest-asyncio, mypy-extensions, multidict, MarkupSafe, joblib, idna, h11, greenlet, fsspec, frozenlist, distro, diskcache, click, charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, python-dateutil, pydantic-core, nltk, marshmallow, jinja2, httpcore, deprecated, anyio, aiosignal, tiktoken, pydantic, pandas, llama-cpp-python, httpx, dataclasses-json, aiohttp, openai, llamaindex-py-client, llama-index-core, llama-index-llms-llama-cpp\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pytz-2024.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pytz/\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: dirtyjson\n",
      "    Found existing installation: dirtyjson 1.0.8\n",
      "    Uninstalling dirtyjson-1.0.8:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/dirtyjson-1.0.8.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/dirtyjson/\n",
      "      Successfully uninstalled dirtyjson-1.0.8\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.16.0\n",
      "    Uninstalling wrapt-1.16.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/wrapt-1.16.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/wrapt/\n",
      "      Successfully uninstalled wrapt-1.16.0\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/urllib3-2.2.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/urllib3/\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: tzdata\n",
      "    Found existing installation: tzdata 2024.1\n",
      "    Uninstalling tzdata-2024.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tzdata-2024.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tzdata/\n",
      "      Successfully uninstalled tzdata-2024.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/__pycache__/typing_extensions.cpython-311.pyc\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/typing_extensions-4.10.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/typing_extensions.py\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.2\n",
      "    Uninstalling tqdm-4.66.2:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/tqdm\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tqdm-4.66.2.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tqdm/\n",
      "      Successfully uninstalled tqdm-4.66.2\n",
      "  changing mode of /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/tqdm to 755\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.3\n",
      "    Uninstalling tenacity-8.2.3:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tenacity-8.2.3.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tenacity/\n",
      "      Successfully uninstalled tenacity-8.2.3\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.3.1\n",
      "    Uninstalling sniffio-1.3.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/sniffio-1.3.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/sniffio/\n",
      "      Successfully uninstalled sniffio-1.3.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/__pycache__/six.cpython-311.pyc\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/six-1.16.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/six.py\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: regex\n",
      "    Found existing installation: regex 2023.12.25\n",
      "    Uninstalling regex-2023.12.25:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/regex-2023.12.25.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/regex/\n",
      "      Successfully uninstalled regex-2023.12.25\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/PyYAML-6.0.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/_yaml/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/yaml/\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 10.2.0\n",
      "    Uninstalling pillow-10.2.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/PIL/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pillow-10.2.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pillow.libs/\n",
      "      Successfully uninstalled pillow-10.2.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/packaging-24.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/packaging/\n",
      "      Successfully uninstalled packaging-24.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/f2py\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/numpy-1.26.4.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/numpy.libs/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/numpy/\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  changing mode of /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/f2py to 755\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 3.2.1\n",
      "    Uninstalling networkx-3.2.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/networkx-3.2.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/networkx/\n",
      "      Successfully uninstalled networkx-3.2.1\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.6.0\n",
      "    Uninstalling nest-asyncio-1.6.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/__pycache__/nest_asyncio.cpython-311.pyc\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/nest_asyncio-1.6.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/nest_asyncio.py\n",
      "      Successfully uninstalled nest-asyncio-1.6.0\n",
      "  Attempting uninstall: mypy-extensions\n",
      "    Found existing installation: mypy-extensions 1.0.0\n",
      "    Uninstalling mypy-extensions-1.0.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/__pycache__/mypy_extensions.cpython-311.pyc\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/mypy_extensions-1.0.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/mypy_extensions.py\n",
      "      Successfully uninstalled mypy-extensions-1.0.0\n",
      "  Attempting uninstall: multidict\n",
      "    Found existing installation: multidict 6.0.5\n",
      "    Uninstalling multidict-6.0.5:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/multidict-6.0.5.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/multidict/\n",
      "      Successfully uninstalled multidict-6.0.5\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 2.1.5\n",
      "    Uninstalling MarkupSafe-2.1.5:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/MarkupSafe-2.1.5.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/markupsafe/\n",
      "      Successfully uninstalled MarkupSafe-2.1.5\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.3.2\n",
      "    Uninstalling joblib-1.3.2:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/joblib-1.3.2.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/joblib/\n",
      "      Successfully uninstalled joblib-1.3.2\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.6\n",
      "    Uninstalling idna-3.6:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/idna-3.6.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/idna/\n",
      "      Successfully uninstalled idna-3.6\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/h11-0.14.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/h11/\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.0.3\n",
      "    Uninstalling greenlet-3.0.3:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/include/python3.11/greenlet/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/greenlet-3.0.3.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/greenlet/\n",
      "      Successfully uninstalled greenlet-3.0.3\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.1\n",
      "    Uninstalling fsspec-2024.3.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/fsspec-2024.3.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/fsspec/\n",
      "      Successfully uninstalled fsspec-2024.3.1\n",
      "  Attempting uninstall: frozenlist\n",
      "    Found existing installation: frozenlist 1.4.1\n",
      "    Uninstalling frozenlist-1.4.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/frozenlist-1.4.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/frozenlist/\n",
      "      Successfully uninstalled frozenlist-1.4.1\n",
      "  Attempting uninstall: distro\n",
      "    Found existing installation: distro 1.9.0\n",
      "    Uninstalling distro-1.9.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/distro\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/distro-1.9.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/distro/\n",
      "      Successfully uninstalled distro-1.9.0\n",
      "  changing mode of /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/distro to 755\n",
      "  Attempting uninstall: diskcache\n",
      "    Found existing installation: diskcache 5.6.3\n",
      "    Uninstalling diskcache-5.6.3:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/diskcache-5.6.3.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/diskcache/\n",
      "      Successfully uninstalled diskcache-5.6.3\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.1.7\n",
      "    Uninstalling click-8.1.7:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/click-8.1.7.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/click/\n",
      "      Successfully uninstalled click-8.1.7\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 3.3.2\n",
      "    Uninstalling charset-normalizer-3.3.2:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/normalizer\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/charset_normalizer-3.3.2.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/charset_normalizer/\n",
      "      Successfully uninstalled charset-normalizer-3.3.2\n",
      "  changing mode of /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/normalizer to 755\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.2.2\n",
      "    Uninstalling certifi-2024.2.2:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/certifi-2024.2.2.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/certifi/\n",
      "      Successfully uninstalled certifi-2024.2.2\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.2.0\n",
      "    Uninstalling attrs-23.2.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/attr/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/attrs-23.2.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/attrs/\n",
      "      Successfully uninstalled attrs-23.2.0\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.6.0\n",
      "    Uninstalling annotated-types-0.6.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/annotated_types-0.6.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/annotated_types/\n",
      "      Successfully uninstalled annotated-types-0.6.0\n",
      "  Attempting uninstall: yarl\n",
      "    Found existing installation: yarl 1.9.4\n",
      "    Uninstalling yarl-1.9.4:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/yarl-1.9.4.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/yarl/\n",
      "      Successfully uninstalled yarl-1.9.4\n",
      "  Attempting uninstall: typing-inspect\n",
      "    Found existing installation: typing-inspect 0.9.0\n",
      "    Uninstalling typing-inspect-0.9.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/__pycache__/typing_inspect.cpython-311.pyc\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/typing_inspect-0.9.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/typing_inspect.py\n",
      "      Successfully uninstalled typing-inspect-0.9.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.28\n",
      "    Uninstalling SQLAlchemy-2.0.28:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/SQLAlchemy-2.0.28.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/sqlalchemy/\n",
      "      Successfully uninstalled SQLAlchemy-2.0.28\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/requests-2.31.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/requests/\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/dateutil/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/python_dateutil-2.9.0.post0.dist-info/\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.16.3\n",
      "    Uninstalling pydantic_core-2.16.3:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pydantic_core-2.16.3.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pydantic_core/\n",
      "      Successfully uninstalled pydantic_core-2.16.3\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.8.1\n",
      "    Uninstalling nltk-3.8.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/nltk\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/nltk-3.8.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/nltk/\n",
      "      Successfully uninstalled nltk-3.8.1\n",
      "  changing mode of /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/nltk to 755\n",
      "  Attempting uninstall: marshmallow\n",
      "    Found existing installation: marshmallow 3.21.1\n",
      "    Uninstalling marshmallow-3.21.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/marshmallow-3.21.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/marshmallow/\n",
      "      Successfully uninstalled marshmallow-3.21.1\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.3\n",
      "    Uninstalling Jinja2-3.1.3:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/Jinja2-3.1.3.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/jinja2/\n",
      "      Successfully uninstalled Jinja2-3.1.3\n",
      "  Attempting uninstall: httpcore\n",
      "    Found existing installation: httpcore 1.0.4\n",
      "    Uninstalling httpcore-1.0.4:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/httpcore-1.0.4.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/httpcore/\n",
      "      Successfully uninstalled httpcore-1.0.4\n",
      "  Attempting uninstall: deprecated\n",
      "    Found existing installation: Deprecated 1.2.14\n",
      "    Uninstalling Deprecated-1.2.14:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/Deprecated-1.2.14.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/deprecated/\n",
      "      Successfully uninstalled Deprecated-1.2.14\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.3.0\n",
      "    Uninstalling anyio-4.3.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/anyio-4.3.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/anyio/\n",
      "      Successfully uninstalled anyio-4.3.0\n",
      "  Attempting uninstall: aiosignal\n",
      "    Found existing installation: aiosignal 1.3.1\n",
      "    Uninstalling aiosignal-1.3.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/aiosignal-1.3.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/aiosignal/\n",
      "      Successfully uninstalled aiosignal-1.3.1\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.6.0\n",
      "    Uninstalling tiktoken-0.6.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tiktoken-0.6.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tiktoken/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/tiktoken_ext/\n",
      "      Successfully uninstalled tiktoken-0.6.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.6.4\n",
      "    Uninstalling pydantic-2.6.4:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pydantic-2.6.4.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pydantic/\n",
      "      Successfully uninstalled pydantic-2.6.4\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.1\n",
      "    Uninstalling pandas-2.2.1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pandas-2.2.1.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/pandas/\n",
      "      Successfully uninstalled pandas-2.2.1\n",
      "  Attempting uninstall: llama-cpp-python\n",
      "    Found existing installation: llama_cpp_python 0.2.57\n",
      "    Uninstalling llama_cpp_python-0.2.57:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/bin/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/include/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/lib/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llama_cpp/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llama_cpp_python-0.2.57.dist-info/\n",
      "      Successfully uninstalled llama_cpp_python-0.2.57\n",
      "  Attempting uninstall: httpx\n",
      "    Found existing installation: httpx 0.27.0\n",
      "    Uninstalling httpx-0.27.0:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/httpx\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/httpx-0.27.0.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/httpx/\n",
      "      Successfully uninstalled httpx-0.27.0\n",
      "  changing mode of /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/httpx to 755\n",
      "  Attempting uninstall: dataclasses-json\n",
      "    Found existing installation: dataclasses-json 0.6.4\n",
      "    Uninstalling dataclasses-json-0.6.4:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/dataclasses_json-0.6.4.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/dataclasses_json/\n",
      "      Successfully uninstalled dataclasses-json-0.6.4\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.9.3\n",
      "    Uninstalling aiohttp-3.9.3:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/aiohttp-3.9.3.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/aiohttp/\n",
      "      Successfully uninstalled aiohttp-3.9.3\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.14.2\n",
      "    Uninstalling openai-1.14.2:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/openai\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/openai-1.14.2.dist-info/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/openai/\n",
      "      Successfully uninstalled openai-1.14.2\n",
      "  changing mode of /home/mjknowles/anaconda3/envs/rag-from-scratch/bin/openai to 755\n",
      "  Attempting uninstall: llamaindex-py-client\n",
      "    Found existing installation: llamaindex-py-client 0.1.13\n",
      "    Uninstalling llamaindex-py-client-0.1.13:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llama_index_client/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llamaindex_py_client-0.1.13.dist-info/\n",
      "      Successfully uninstalled llamaindex-py-client-0.1.13\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.21.post1\n",
      "    Uninstalling llama-index-core-0.10.21.post1:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llama_index/core/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llama_index_core-0.10.21.post1.dist-info/\n",
      "      Successfully uninstalled llama-index-core-0.10.21.post1\n",
      "  Attempting uninstall: llama-index-llms-llama-cpp\n",
      "    Found existing installation: llama-index-llms-llama-cpp 0.1.3\n",
      "    Uninstalling llama-index-llms-llama-cpp-0.1.3:\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llama_index/llms/llama_cpp/\n",
      "      Removing file or directory /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages/llama_index_llms_llama_cpp-0.1.3.dist-info/\n",
      "      Successfully uninstalled llama-index-llms-llama-cpp-0.1.3\n",
      "Successfully installed MarkupSafe-2.1.5 PyYAML-6.0.1 SQLAlchemy-2.0.28 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 attrs-23.2.0 certifi-2024.2.2 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 diskcache-5.6.3 distro-1.9.0 frozenlist-1.4.1 fsspec-2024.3.1 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 idna-3.6 jinja2-3.1.3 joblib-1.3.2 llama-cpp-python-0.2.57 llama-index-core-0.10.21.post1 llama-index-llms-llama-cpp-0.1.3 llamaindex-py-client-0.1.13 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.8.1 numpy-1.26.4 openai-1.14.2 packaging-24.0 pandas-2.2.1 pillow-10.2.0 pydantic-2.6.4 pydantic-core-2.16.3 python-dateutil-2.9.0.post0 pytz-2024.1 regex-2023.12.25 requests-2.31.0 six-1.16.0 sniffio-1.3.1 tenacity-8.2.3 tiktoken-0.6.0 tqdm-4.66.2 typing-extensions-4.10.0 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.1 wrapt-1.16.0 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#cpu\n",
    "#%env CMAKE_ARGS=\"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\"\n",
    "#cuda\n",
    "#%env CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" \n",
    "#%env FORCE_CMAKE=1\n",
    "#%env CUDAFLAGS=\"-arch=all -lcublas\"\n",
    "#%pip install llama-cpp-python --upgrade --force-reinstall --no-cache-dir --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install llama-index-llms-llama-cpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import hf_hub_download\n",
    "#hf_hub_download(repo_id='TheBloke/Mistral-7B-v0.1-GGUF', filename='mistral-7b-v0.1.Q4_K_M.gguf', local_dir='./models', local_dir_use_symlinks=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from models/mistral-7b-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: causal attn      = 1\n",
      "llm_load_print_meta: pooling type     = 0\n",
      "llm_load_print_meta: rope type        = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: ssm_d_conv       = 0\n",
      "llm_load_print_meta: ssm_d_inner      = 0\n",
      "llm_load_print_meta: ssm_d_state      = 0\n",
      "llm_load_print_meta: ssm_dt_rank      = 0\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors:        CPU buffer size =  4165.37 MiB\n",
      ".................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 3900\n",
      "llama_new_context_with_model: n_batch    = 512\n",
      "llama_new_context_with_model: n_ubatch   = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   487.50 MiB\n",
      "llama_new_context_with_model: KV self size  =  487.50 MiB, K (f16):  243.75 MiB, V (f16):  243.75 MiB\n",
      "llama_new_context_with_model:        CPU  output buffer size =    62.50 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   283.37 MiB\n",
      "llama_new_context_with_model: graph nodes  = 1060\n",
      "llama_new_context_with_model: graph splits = 1\n",
      "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 1 | AVX512_VNNI = 1 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.rope.freq_base': '10000.000000', 'llama.context_length': '32768', 'general.name': 'mistralai_mistral-7b-v0.1', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '14336', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'tokenizer.ggml.bos_token_id': '1', 'llama.attention.head_count': '32', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
      "Using fallback chat format: None\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.llama_cpp import LlamaCPP\n",
    "\n",
    "# model_url = \"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf\"\n",
    "model_url = \"https://huggingface.co/TheBloke/Mistral-7B-v0.1-GGUF/resolve/main/mistral-7b-v0.1.Q4_K_M.gguf\"\n",
    "\n",
    "llm = LlamaCPP(\n",
    "    # You can pass in the URL to a GGML model to download it automatically\n",
    "    model_url=None,\n",
    "    # optionally, you can set the path to a pre-downloaded model instead of model_url\n",
    "    model_path='models/mistral-7b-v0.1.Q4_K_M.gguf',\n",
    "    temperature=0.1,\n",
    "    max_new_tokens=256,\n",
    "    # llama2 has a context window of 4096 tokens, but we set it lower to allow for some wiggle room\n",
    "    context_window=3900,\n",
    "    # kwargs to pass to __call__()\n",
    "    generate_kwargs={},\n",
    "    # kwargs to pass to __init__()\n",
    "    # set to at least 1 to use GPU\n",
    "    model_kwargs={\"n_gpu_layers\": 15000},\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (2.9.9)\n",
      "Requirement already satisfied: pgvector in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (0.2.5)\n",
      "Requirement already satisfied: asyncpg in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (0.29.0)\n",
      "Requirement already satisfied: greenlet in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (3.0.3)\n",
      "Requirement already satisfied: sqlalchemy[asyncio] in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (2.0.28)\n",
      "Requirement already satisfied: numpy in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from pgvector) (1.26.4)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from asyncpg) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/mjknowles/anaconda3/envs/rag-from-scratch/lib/python3.11/site-packages (from sqlalchemy[asyncio]) (4.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2-binary pgvector asyncpg \"sqlalchemy[asyncio]\" greenlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psycopg2\n",
    "\n",
    "# db_name = \"vector_db\"\n",
    "# host = \"localhost\"\n",
    "# password = \"postgres\"\n",
    "# port = \"5432\"\n",
    "# user = \"postgres\"\n",
    "# # conn = psycopg2.connect(connection_string)\n",
    "# conn = psycopg2.connect(\n",
    "#     dbname=postgres,\n",
    "#     host=host,\n",
    "#     password=password,\n",
    "#     port=port,\n",
    "#     user=user,\n",
    "# )\n",
    "# conn.autocommit = True\n",
    "\n",
    "# with conn.cursor() as c:\n",
    "#     c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "#     c.execute(f\"CREATE DATABASE {db_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "db_name = \"vectordb\"\n",
    "# host = \"db\"\n",
    "host = \"localhost\"\n",
    "password = \"testpwd\"\n",
    "port = \"5432\"\n",
    "user = \"testuser\"\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    table_name=\"llama2_paper\",\n",
    "    embed_dim=384,  # openai embedding dimension\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%mkdir data\n",
    "#%wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2307.09288.pdf\" -O \"data/llama2.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader\n",
    "\n",
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"./data/llama2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    # separator=\" \",\n",
    ")\n",
    "\n",
    "text_chunks = []\n",
    "# maintain relationship with source doc index, to help inject doc metadata in (3)\n",
    "doc_idxs = []\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    cur_text_chunks = text_parser.split_text(doc.text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = []\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    src_doc = documents[doc_idxs[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cd48d839-0870-4881-9e99-089cc527daaf',\n",
       " 'f9a104a3-c04c-4eb8-a0b0-cef35d99076f',\n",
       " '455f7c23-b980-456f-b952-b30f19d7494a',\n",
       " 'c26d4d6c-56d1-484f-8726-009e930d749d',\n",
       " '41dae9b9-b904-4063-8fce-0045eed1da79',\n",
       " '17e612b3-a576-4022-a6b4-d3463d889111',\n",
       " 'bbe3ed3f-d062-46cd-b3fd-071f30dc47a7',\n",
       " 'cef9c441-3e02-49d6-81dc-9dd593738a70',\n",
       " '5984fb4a-5f14-4f65-8f11-cd9a97603b60',\n",
       " '4d591297-e628-4756-94e3-6f545fa7a098',\n",
       " '649db18a-8e43-40d0-b25e-7397fc53baa7',\n",
       " 'ff79b38e-4bf6-4735-afa0-696246a83d19',\n",
       " '3626ea86-86cb-4689-97e9-ef8c599a2f77',\n",
       " '1b4a635c-8e2f-427f-aa14-312df8732543',\n",
       " 'cbf263f4-1c2b-4281-86a4-edd20a2a51c2',\n",
       " '442e080e-ccbb-4eca-8ccf-131e9d4c76fb',\n",
       " '108f9853-b1a5-46d9-9b38-177a80082701',\n",
       " '0b6d06e8-a812-4e3c-863a-124790a43bc7',\n",
       " '64437939-ae03-4e84-9d8f-8d5445cf2cf8',\n",
       " 'df09c129-323f-49be-b1b7-49ad5d10de1c',\n",
       " '94bfaa87-3d92-4fa0-b818-1ad991b86965',\n",
       " '18dda521-5faa-4f16-9e91-f6f687543cba',\n",
       " '0aa2bb2a-39fc-48e5-8872-b988f2d7ba18',\n",
       " 'ea685646-81c1-4b25-88a5-3100a4977152',\n",
       " 'e10ebe22-75a8-44f9-b6a5-4ca120753462',\n",
       " 'c8907445-93c7-43e5-a77b-93a2ca20f75f',\n",
       " '0f49c5f6-0191-4067-a8c7-ad5cdb60a31c',\n",
       " '481589d0-60f5-4ab5-845c-a77ddc148f10',\n",
       " 'd2fefddc-b427-4354-8dd5-49370b2f1333',\n",
       " 'bf58f977-b9bd-44f3-9bd6-178361f0c71a',\n",
       " '1bff1591-9fe6-43c6-9586-33aaf9232487',\n",
       " 'ae756954-e825-4afe-8596-649e24f77e2f',\n",
       " '6ce5b6b8-9ca8-4d1e-8cb1-3931d1d99309',\n",
       " '9f232973-3f57-4855-908f-5e6e77d9188f',\n",
       " '7a65fbb8-ff8d-4ce1-a1e1-3cccd5706681',\n",
       " 'f30ee43e-5c1d-4974-acbc-861958f50d3f',\n",
       " '59ddaf27-5e5d-4e0f-9e86-a08565dd9067',\n",
       " '0e769b2c-28cb-4e26-97ae-007f30eef1e6',\n",
       " 'a2fa343b-a421-4a48-8f83-542182230870',\n",
       " 'd5cdafd4-4008-434c-936d-1bd2d73fffeb',\n",
       " 'b4776325-2d1b-412f-be34-ac807dc5665b',\n",
       " '0bcd6033-428c-42cf-b8b9-f0aa9811b1fc',\n",
       " '2bc5a20c-702c-4aef-b1f2-c7f9367f482c',\n",
       " '6ba89369-c110-4ef3-bbbf-334f769e0073',\n",
       " '9773b2e8-26ee-462e-9ed7-994b68e64d75',\n",
       " '532756dc-f9d6-4998-94fd-d214d887dad3',\n",
       " 'dee469dc-7304-4ea5-89a7-e991cec07647',\n",
       " '0ecf0e0d-6ab2-4572-aca0-e4b591fd6dad',\n",
       " '28be0372-0bde-4a4c-bc9f-d605ab0e5434',\n",
       " '9979c350-5749-42fd-938d-0eecd11af519',\n",
       " 'ea82d42e-1f05-46c2-92cf-83431b2ca94c',\n",
       " '607d9090-e3e4-47be-9222-8214411f1847',\n",
       " '2968cce1-925d-4c76-ab10-a5cf0bed4772',\n",
       " 'b14deff8-c744-4e08-bb45-08ac14115332',\n",
       " 'dcb8db16-c88c-481d-ac53-ba6c2f8b33ea',\n",
       " '4391f751-b049-420e-9dab-8d34fb4674b7',\n",
       " 'cd70f58a-f600-48e3-ab1d-ce6d01d632ee',\n",
       " 'f48b2f01-1068-4017-9dca-31a2ce456d1c',\n",
       " '737492b8-d0e8-4fa0-98c7-c50ccbb2d0f7',\n",
       " '38dba476-53a5-45f0-a4a5-c05f8a47ec52',\n",
       " 'a5c99941-3c01-4b2d-825b-ad3b48bf740f',\n",
       " 'cf516f8e-5f6c-48d8-911d-a544d8edbe01',\n",
       " '2e33214b-53a5-4dfe-b4a8-d7fb94c2665f',\n",
       " 'e12fdddf-ae1e-41d0-bfec-809d821f0ba4',\n",
       " 'c50e8cbc-2d90-410a-995e-a809026664b9',\n",
       " '9b61b36a-5b7f-4d5d-ac19-9a53e313f703',\n",
       " '7350e1b7-2c31-439f-9200-0b20ddd147b7',\n",
       " '249417e7-34d4-485d-bfaa-a955a77b0d73',\n",
       " 'a05d89b0-bf7e-4c79-8f07-e8cd49812635',\n",
       " '6e25fe23-112f-4df1-ae3f-e3d015b0f665',\n",
       " 'fff2bcb1-17af-43ee-be9b-4a9cdd5fa2a4',\n",
       " '18127f44-4736-45be-b9ae-74d1c43153f4',\n",
       " 'ab90d636-4807-4de7-a05b-777f7c29f5ea',\n",
       " 'aa985129-7c6d-4f12-8c48-c4e236795a3c',\n",
       " 'aed5b55e-1778-4ca2-9c44-8cc41d43e0e9',\n",
       " '37d4a4d7-de56-4e23-be91-6b232be4e2b8',\n",
       " 'e10b0236-0eb6-4b06-a937-9ac8957985cb',\n",
       " 'c31b4851-1500-4c0b-864d-9974ad13fe14',\n",
       " '514f8d04-fec6-4295-ae39-7f36b1fab795',\n",
       " '31372edc-5bc1-4c58-8646-c0f3ae539537',\n",
       " '7e19f516-09f0-4923-bb74-d0023b685df2',\n",
       " 'abaf9e13-edb2-4f25-a22e-39bc32e5d883',\n",
       " 'aba573ae-0612-4813-8ce8-9ca03403ce3c',\n",
       " 'e4e304c8-2ed3-4721-8ce2-0cbfda746650',\n",
       " '86753576-3207-45da-b496-a3c2322b9c69',\n",
       " 'eb526237-8213-4a11-a313-a00795275ee2',\n",
       " '59ae08c5-2ad9-4db7-84b1-2aa649580b19',\n",
       " '33fa760f-cfce-4cd4-b90b-01f544e14e2a',\n",
       " '410a76ce-4049-467a-b21e-d5d2ddbd74e0',\n",
       " '5cf4c2ee-3af5-4b2e-9f06-43070ecedb5e',\n",
       " 'bfe24b90-5432-4b98-b6e7-519755b27e8c',\n",
       " '33d65aae-743a-4492-81f2-290cd12b6bfb',\n",
       " '8b101caa-8335-4976-905c-e63d3ef63fc5',\n",
       " 'b1216346-9b13-46f8-a7ab-660571d05b36',\n",
       " '549c7883-b9cb-487e-b543-66714a0207a4',\n",
       " 'bb7b3e7d-c32c-4c46-bfdf-3350a2bbc1df',\n",
       " '5ec44650-100f-4c5d-b140-bea405fb153c',\n",
       " '60f84edc-2cda-472b-93b9-0c74da12e20a',\n",
       " '11877f97-46d8-409d-ad0f-6b72d6e9fe69',\n",
       " 'b1bc83d6-338d-4129-8f3c-502cf9006522',\n",
       " 'ef98895e-27eb-4b4a-b873-9b6308720834',\n",
       " 'dee698d4-de57-4370-948a-ddf8bd697588',\n",
       " '5bb7528c-d503-45ec-aaa6-36bafb868f94',\n",
       " '2301334b-f1aa-4e62-85ca-043ecb1fc9ab',\n",
       " '4d18be5e-06f1-4b63-b56e-de86dc296b9e',\n",
       " 'e42ab4a9-d2df-41ef-9e89-007687734028',\n",
       " '6b9f0843-e34d-487c-90af-36a8a6dbc944']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Can you tell me about the key concepts for safety finetuning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embed_model.get_query_embedding(query_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "\n",
    "query_mode = \"default\"\n",
    "# query_mode = \"sparse\"\n",
    "# query_mode = \"hybrid\"\n",
    "\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruthfulQA ↑\n",
      "ToxiGen ↓\n",
      "MPT\n",
      "7B\n",
      "29.13\n",
      "22.32\n",
      "30B\n",
      "35.25\n",
      "22.61\n",
      "Falcon\n",
      "7B\n",
      "25.95\n",
      "14.53\n",
      "40B\n",
      "40.39\n",
      "23.44\n",
      "Llama 1\n",
      "7B\n",
      "27.42\n",
      "23.00\n",
      "13B\n",
      "41.74\n",
      "23.08\n",
      "33B\n",
      "44.19\n",
      "22.57\n",
      "65B\n",
      "48.71\n",
      "21.77\n",
      "Llama 2\n",
      "7B\n",
      "33.29\n",
      "21.25\n",
      "13B\n",
      "41.86\n",
      "26.10\n",
      "34B\n",
      "43.45\n",
      "21.19\n",
      "70B\n",
      "50.18\n",
      "24.60\n",
      "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\n",
      "percentage of generations that are both truthful and informative (the higher the better). For ToxiGen, we\n",
      "present the percentage of toxic generations (the smaller, the better).\n",
      "Benchmarks give a summary view of model capabilities and behaviors that allow us to understand general\n",
      "patterns in the model, but they do not provide a fully comprehensive view of the impact the model may have\n",
      "on people or real-world outcomes; that would require study of end-to-end product deployments. Further\n",
      "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
      "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
      "the BOLD dataset (race, religion, and gender). As LLMs are integrated and deployed, we look forward to\n",
      "continuing research that will amplify their potential for positive impact on these important social issues.\n",
      "4.2\n",
      "Safety Fine-Tuning\n",
      "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
      "guidelines, and the techniques we use to mitigate safety risks. We employ a process similar to the general\n",
      "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\n",
      "Specifically, we use the following techniques in safety fine-tuning:\n",
      "1. Supervised Safety Fine-Tuning: We initialize by gathering adversarial prompts and safe demonstra-\n",
      "tions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\n",
      "the model to align with our safety guidelines even before RLHF, and thus lays the foundation for\n",
      "high-quality human preference data annotation.\n",
      "2. Safety RLHF: Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\n",
      "tion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\n",
      "adversarial prompts for rejection sampling style fine-tuning and PPO optimization.\n",
      "3. Safety Context Distillation: Finally, we refine our RLHF pipeline with context distillation (Askell\n",
      "et al., 2021b). This involves generating safer model responses by prefixing a prompt with a safety\n",
      "preprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\n",
      "responses without the preprompt, which essentially distills the safety preprompt (context) into the\n",
      "model. We use a targeted approach that allows our safety reward model to choose whether to use\n",
      "context distillation for each sample.\n",
      "4.2.1\n",
      "Safety Categories and Annotation Guidelines\n",
      "Based on limitations of LLMs known from prior work, we design instructions for our annotation team to\n",
      "create adversarial prompts along two dimensions: a risk category, or potential topic about which the LLM\n",
      "could produce unsafe content; and an attack vector, or question style to cover different varieties of prompts\n",
      "that could elicit bad model behaviors.\n",
      "The risk categories considered can be broadly divided into the following three categories: illicit and criminal\n",
      "activities (e.g., terrorism, theft, human trafficking); hateful and harmful activities (e.g., defamation, self-\n",
      "harm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "query_result = vector_store.query(vector_store_query)\n",
    "print(query_result.nodes[0].get_content())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "nodes_with_scores = []\n",
    "for index, node in enumerate(query_result.nodes):\n",
    "    score: Optional[float] = None\n",
    "    if query_result.similarities is not None:\n",
    "        score = query_result.similarities[index]\n",
    "    nodes_with_scores.append(NodeWithScore(node=node, score=score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from typing import Any, List\n",
    "\n",
    "\n",
    "class VectorDBRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever over a postgres vector store.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: PGVectorStore,\n",
    "        embed_model: Any,\n",
    "        query_mode: str = \"default\",\n",
    "        similarity_top_k: int = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve.\"\"\"\n",
    "        query_embedding = embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_store_query = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode,\n",
    "        )\n",
    "        query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for index, node in enumerate(query_result.nodes):\n",
    "            score: Optional[float] = None\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[index]\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "        return nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorDBRetriever(\n",
    "    vector_store, embed_model, query_mode=\"default\", similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Llama 2 performs better than other open-source models on most benchmarks. 2. Llama 2 performs\n",
      "close to GPT-3.5 on MMLU and GSM8K, but there is a significant gap on coding benchmarks. 3. Llama 2\n",
      "results are on par or better than PaLM on almost all benchmarks. 4. There is still a large gap in performance\n",
      "between Llama 2 and GPT-4 and PaLM-2-L."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   23013.69 ms\n",
      "llama_print_timings:      sample time =      18.31 ms /   115 runs   (    0.16 ms per token,  6282.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =   35743.21 ms /   764 tokens (   46.78 ms per token,    21.37 tokens per second)\n",
      "llama_print_timings:        eval time =   29814.13 ms /   114 runs   (  261.53 ms per token,     3.82 tokens per second)\n",
      "llama_print_timings:       total time =   65801.67 ms /   878 tokens\n"
     ]
    }
   ],
   "source": [
    "query_str = \"How does Llama 2 perform compared to other open-source models?\"\n",
    "\n",
    "response = query_engine.query(query_str)\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Llama 2 performs better than other open-source models on most benchmarks. 2. Llama 2 performs\n",
      "close to GPT-3.5 on MMLU and GSM8K, but there is a significant gap on coding benchmarks. 3. Llama 2\n",
      "results are on par or better than PaLM on almost all benchmarks. 4. There is still a large gap in performance\n",
      "between Llama 2 and GPT-4 and PaLM-2-L.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additionally, Llama 2 70B model outperforms all open-source models.\n",
      "In addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\n",
      "in Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\n",
      "gap on coding benchmarks. Llama 2 70B results are on par or better than PaLM (540B) (Chowdhery et al.,\n",
      "2022) on almost all benchmarks. There is still a large gap in performance between Llama 2 70B and GPT-4\n",
      "and PaLM-2-L.\n",
      "We also analysed the potential data contamination and share the details in Section A.6.\n",
      "Benchmark (shots)\n",
      "GPT-3.5\n",
      "GPT-4\n",
      "PaLM\n",
      "PaLM-2-L\n",
      "Llama 2\n",
      "MMLU (5-shot)\n",
      "70.0\n",
      "86.4\n",
      "69.3\n",
      "78.3\n",
      "68.9\n",
      "TriviaQA (1-shot)\n",
      "–\n",
      "–\n",
      "81.4\n",
      "86.1\n",
      "85.0\n",
      "Natural Questions (1-shot)\n",
      "–\n",
      "–\n",
      "29.3\n",
      "37.5\n",
      "33.0\n",
      "GSM8K (8-shot)\n",
      "57.1\n",
      "92.0\n",
      "56.5\n",
      "80.7\n",
      "56.8\n",
      "HumanEval (0-shot)\n",
      "48.1\n",
      "67.0\n",
      "26.2\n",
      "–\n",
      "29.9\n",
      "BIG-Bench Hard (3-shot)\n",
      "–\n",
      "–\n",
      "52.3\n",
      "65.7\n",
      "51.2\n",
      "Table 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\n",
      "are from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\n",
      "PaLM-2-L are from Anil et al. (2023).\n",
      "3\n",
      "Fine-tuning\n",
      "Llama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\n",
      "including both instruction tuning and RLHF, requiring significant computational and annotation resources.\n",
      "In this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\n",
      "well as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\n",
      "new technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\n",
      "(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7B, 13B, and 70B"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   23013.69 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /    14 runs   (    0.17 ms per token,  5835.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =   50359.80 ms /   997 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_print_timings:        eval time =    3810.49 ms /    13 runs   (  293.11 ms per token,     3.41 tokens per second)\n",
      "llama_print_timings:       total time =   54207.05 ms /  1010 tokens\n"
     ]
    }
   ],
   "source": [
    "query_str = \"What is the parameter count of a Llama 2 model?\"\n",
    "response = query_engine.query(query_str)\n",
    "response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7B, 13B, and 70B\n"
     ]
    }
   ],
   "source": [
    "print(str(response))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
